<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · DelayEmbeddings.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DelayEmbeddings.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><p>Package doesn&#39;t contain Documenter docs.</p><p>Docs automatically generated by juliadocs.org</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.AbstractEmbedding" href="#DelayEmbeddings.AbstractEmbedding"><code>DelayEmbeddings.AbstractEmbedding</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">AbstractEmbedding</code></pre><p>Super-type of embedding methods. Use <code>subtypes(AbstractEmbedding)</code> for available methods.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.AbstractNeighborhood" href="#DelayEmbeddings.AbstractNeighborhood"><code>DelayEmbeddings.AbstractNeighborhood</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">AbstractNeighborhood</code></pre><p>Supertype of methods for deciding the neighborhood of points for a given point.</p><p>Concrete subtypes:</p><ul><li><code>FixedMassNeighborhood(K::Int)</code> : The neighborhood of a point consists of the <code>K</code> nearest neighbors of the point.</li><li><code>FixedSizeNeighborhood(ε::Real)</code> : The neighborhood of a point consists of all neighbors that have distance &lt; <code>ε</code> from the point.</li></ul><p>See <a href="#DelayEmbeddings.neighborhood"><code>neighborhood</code></a> for more.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.Dataset" href="#DelayEmbeddings.Dataset"><code>DelayEmbeddings.Dataset</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Dataset{D, T} &lt;: AbstractDataset{D,T}</code></pre><p>A dedicated interface for datasets. It contains <em>equally-sized datapoints</em> of length <code>D</code>, represented by <code>SVector{D, T}</code>.</p><p>When indexed with 1 index, a <code>dataset</code> is like a vector of datapoints.</p><p>When indexed with 2 indices it behaves like a matrix that has each of the columns be the timeseries of each of the dynamic variables.</p><p><strong>Description of indexing</strong></p><p>In the following let <code>i, j</code> be integers,  <code>typeof(data) &lt;: AbstractDataset</code> and <code>v1, v2</code> be <code>&lt;: AbstractVector{Int}</code> (<code>v1, v2</code> could also be ranges).</p><ul><li><code>data[i]</code> gives the <code>i</code>th datapoint (returns an <code>SVector</code>)</li><li><code>data[v1]</code> will return a vector of datapoints</li><li><code>data[v1, :]</code> using a <code>Colon</code> as a second index will return a <code>Dataset</code> of these points</li><li><code>data[:, j]</code> gives the <code>j</code>th variable timeseries, as <code>Vector</code></li><li><code>data[v1, v2]</code> returns a <code>Dataset</code> with the appropriate entries (first indices being &quot;time&quot;/point index, while second being dynamic variables)</li><li><code>data[i, j]</code> value of the <code>j</code>th variable, at the <code>i</code>th timepoint</li></ul><p>Use <code>Matrix(dataset)</code> or <code>Dataset(matrix)</code> to convert. It is assumed that each <em>column</em> of the <code>matrix</code> is one dynamic variable. If you have various timeseries vectors <code>x, y, z, ...</code> pass them like <code>Dataset(x, y, z, ...)</code>. You can use <code>columns(dataset)</code> to obtain the reverse, i.e. all columns of the dataset in a tuple.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.DelayEmbedding" href="#DelayEmbeddings.DelayEmbedding"><code>DelayEmbeddings.DelayEmbedding</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">DelayEmbedding(γ, τ) -&gt; `embedding`</code></pre><p>Return a delay coordinates embedding structure to be used as a functor, given a timeseries and some index. Calling</p><pre><code class="language-julia">embedding(s, n)</code></pre><p>will create the <code>n</code>-th reconstructed vector of the embedded space, which has <code>γ</code> temporal neighbors with delay(s) <code>τ</code>. See <a href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>reconstruct</code></a> for more.</p><p><strong>Be very careful when choosing <code>n</code>, because <code>@inbounds</code> is used internally.</strong></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.MTDelayEmbedding" href="#DelayEmbeddings.MTDelayEmbedding"><code>DelayEmbeddings.MTDelayEmbedding</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MTDelayEmbedding(γ, τ, B) -&gt; `embedding`</code></pre><p>Return a delay coordinates embedding structure to be used as a functor, given multiple timeseries (<code>B</code> in total), either as a <a href="#DelayEmbeddings.Dataset"><code>Dataset</code></a> or a <code>SizedArray</code>), and some index. Calling</p><pre><code class="language-julia">embedding(s, n)</code></pre><p>will create the <code>n</code>-th reconstructed vector of the embedded space, which has <code>γ</code> temporal neighbors with delay(s) <code>τ</code>. See <a href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>reconstruct</code></a> for more.</p><p><strong>Be very careful when choosing <code>n</code>, because <code>@inbounds</code> is used internally.</strong></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.columns" href="#DelayEmbeddings.columns"><code>DelayEmbeddings.columns</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">columns(dataset) -&gt; x, y, z, ...</code></pre><p>Return the individual columns of the dataset.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.embed-Tuple{Any,Any,Any}" href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>DelayEmbeddings.embed</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">embed(s, D, τ)</code></pre><p>Perform a delay coordinates embedding on signal <code>s</code> with embedding dimension <code>D</code> and delay time <code>τ</code>. The result is returned as a <a href="#DelayEmbeddings.Dataset"><code>Dataset</code></a>, which is a vector of static vectors.</p><p>See <a href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>reconstruct</code></a> for an advanced version that supports multiple delay times and can reconstruct multiple timeseries efficiently.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.estimate_delay" href="#DelayEmbeddings.estimate_delay"><code>DelayEmbeddings.estimate_delay</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">estimate_delay(s, method::String [, τs = 1:2:100]; kwargs...) -&gt; τ</code></pre><p>Estimate an optimal delay to be used in <a href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>reconstruct</code></a> or <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>. The <code>method</code> can be one of the following:</p><ul><li><code>&quot;ac_zero&quot;</code> : first delay at which the auto-correlation function becomes &lt;0.</li><li><code>&quot;ac_min&quot;</code> : delay of first minimum of the auto-correlation function.</li><li><code>&quot;mi_min&quot;</code> : delay of first minimum of mutual information of <code>s</code> with itself (shifted for various <code>τs</code>). Keywords <code>nbins, binwidth</code> are propagated into <a href="#DelayEmbeddings.mutualinformation-Union{Tuple{T}, Tuple{AbstractArray{T,1},AbstractArray{Int64,1}}} where T"><code>mutualinformation</code></a>.</li><li><code>&quot;exp_decay&quot;</code> : <a href="#DelayEmbeddings.exponential_decay_fit"><code>exponential_decay_fit</code></a> of the correlation function rounded  to an integer (uses least squares on <code>c(t) = exp(-t/τ)</code> to find <code>τ</code>).</li><li><code>&quot;exp_extrema&quot;</code> : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.</li></ul><p>Both the mutual information and correlation function (<code>autocor</code>) are computed <em>only</em> for delays <code>τs</code>. This means that the <code>min</code> methods can never return the first value of <code>τs</code>!</p><p>The method <code>mi_min</code> is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.estimate_dimension" href="#DelayEmbeddings.estimate_dimension"><code>DelayEmbeddings.estimate_dimension</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">estimate_dimension(s::AbstractVector, τ::Int, γs = 1:5, method = &quot;afnn&quot;; kwargs...)</code></pre><p>Compute a quantity that can estimate an optimal amount of temporal neighbors <code>γ</code> to be used in <a href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>reconstruct</code></a> or <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>.</p><p><strong>Description</strong></p><p>Given the scalar timeseries <code>s</code> and the embedding delay <code>τ</code> compute a quantity for each <code>γ ∈ γs</code> based on the &quot;nearest neighbors&quot; in the embedded time series.</p><p>The quantity that is calculated depends on the algorithm defined by the string <code>method</code>:</p><ul><li><code>&quot;afnn&quot;</code> (default) is Cao&#39;s &quot;Averaged False Nearest Neighbors&quot; method [1], which   gives a ratio of distances between nearest neighbors. This ratio saturates   around <code>1.0</code> near the optimal value of <code>γ</code> (see <a href="#DelayEmbeddings.afnn-Union{Tuple{T}, Tuple{AbstractArray{T,1},Int64}, Tuple{AbstractArray{T,1},Int64,Any}, Tuple{AbstractArray{T,1},Int64,Any,Any}} where T"><code>afnn</code></a>).</li><li><code>&quot;fnn&quot;</code> is Kennel&#39;s &quot;False Nearest Neighbors&quot; method [2], which gives the   number of points that cease to be &quot;nearest neighbors&quot; when the dimension   increases. This number drops down to zero near the optimal value of <code>γ</code>.   This method accepts the keyword arguments <code>rtol</code> and <code>atol</code>, which stand   for the &quot;tolerances&quot; required by Kennel&#39;s algorithm (see <a href="#DelayEmbeddings.fnn"><code>fnn</code></a>).</li><li><code>&quot;f1nn&quot;</code> is Krakovská&#39;s &quot;False First Nearest Neighbors&quot; method [3], which   gives the ratio of pairs of points that cease to be &quot;nearest neighbors&quot;   when the dimension increases. This number drops down to zero near the   optimal value of <code>γ</code> (see <a href="#DelayEmbeddings.f1nn"><code>f1nn</code></a>).</li></ul><p><code>&quot;afnn&quot;</code> and <code>&quot;f1nn&quot;</code> also support the <code>metric</code> keyword, which can be any of <code>Cityblock(), Euclidean(), Chebyshev()</code>. This metric is used both for computing the nearest neighbors (<code>KDTree</code>s) as well as the distances necessary for Cao&#39;s method (eqs. (2, 3) of [1]). Defaults to <code>Euclidean()</code> (note that [1] used <code>Chebyshev</code>).</p><p>Please be aware that in <strong>DynamicalSystems.jl</strong> <code>γ</code> stands for the amount of temporal neighbors and not the embedding dimension (<code>D = γ + 1</code>, see also <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>).</p><p><strong>References</strong></p><p>[1] : Liangyue Cao, <a href="https://www.sciencedirect.com/science/article/pii/S0167278997001188?via%3Dihub">Physica D, pp. 43-50 (1997)</a></p><p>[2] : M. Kennel <em>et al.</em>, <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.45.3403">Phys. Review A <strong>45</strong>(6), 3403-3411</a> (1992).</p><p>[3] : Anna Krakovská <em>et al.</em>, <a href="https://doi.org/10.1155/2015/932750">J. Complex Sys. 932750 (2015)</a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.exponential_decay_fit" href="#DelayEmbeddings.exponential_decay_fit"><code>DelayEmbeddings.exponential_decay_fit</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">exponential_decay_fit(x, y, weight = :equal) -&gt; τ</code></pre><p>Perform a least square fit of the form <code>y = exp(-x/τ)</code> and return <code>τ</code>. Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of <code>x, y</code> and that <code>y ≥ 0</code>.</p><p>To use the method that gives more weight to small values of <code>y</code>, use <code>weight = :small</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.maxima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D" href="#DelayEmbeddings.maxima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D"><code>DelayEmbeddings.maxima</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">maxima(dataset)</code></pre><p>Return an <code>SVector</code> that contains the maximum elements of each timeseries of the dataset.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.min_pairwise_distance-Tuple{AbstractArray{T,2} where T}" href="#DelayEmbeddings.min_pairwise_distance-Tuple{AbstractArray{T,2} where T}"><code>DelayEmbeddings.min_pairwise_distance</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">min_pairwise_distance(data) -&gt; (min_pair, min_dist)</code></pre><p>Calculate the minimum pairwise distance in the data (<code>Matrix</code>, <code>Vector{Vector}</code> or <code>Dataset</code>). Return the index pair of the datapoints that have the minimum distance, as well as its value.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.minima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D" href="#DelayEmbeddings.minima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D"><code>DelayEmbeddings.minima</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">minima(dataset)</code></pre><p>Return an <code>SVector</code> that contains the minimum elements of each timeseries of the dataset.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.minmaxima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D" href="#DelayEmbeddings.minmaxima-Union{Tuple{AbstractDataset{D,T}}, Tuple{T}, Tuple{D}} where T&lt;:Real where D"><code>DelayEmbeddings.minmaxima</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">minmaxima(dataset)</code></pre><p>Return <code>minima(dataset), maxima(dataset)</code> without doing the computation twice.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.mutualinformation-Union{Tuple{T}, Tuple{AbstractArray{T,1},AbstractArray{Int64,1}}} where T" href="#DelayEmbeddings.mutualinformation-Union{Tuple{T}, Tuple{AbstractArray{T,1},AbstractArray{Int64,1}}} where T"><code>DelayEmbeddings.mutualinformation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">mutualinformation(s, τs[; nbins, binwidth])</code></pre><p>Calculate the mutual information between the time series <code>s</code> and its images delayed by <code>τ</code> points for <code>τ</code> ∈ <code>τs</code>, using an <em>improvement</em> of the method outlined by Fraser &amp; Swinney in [1].</p><p><strong>Description</strong></p><p>The joint space of <code>s</code> and its <code>τ</code>-delayed image (<code>sτ</code>) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of <code>s</code> and <code>sτ</code> in the grid as defined in [1]. The mutual information values are returned in a vector of the same length as <code>τs</code>.</p><p>If any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where <code>s</code> and <code>sτ</code> are defined. The margins of that partition will be divided in a number of bins equal to <code>nbins</code>, such that the width of each bin will be <code>binwidth</code>, and the range of nonzero values of <code>s</code> will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where <code>s</code> and <code>sτ</code> are nonzero.</p><p>If no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].</p><p>Notice that the recursive method of [1] evaluates the joint frequencies of <code>s</code> and <code>sτ</code> in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of <code>s</code>.</p><p><strong>References</strong></p><p>[1]: Fraser A.M. &amp; Swinney H.L. &quot;Independent coordinates for strange attractors from mutual information&quot; <em>Phys. Rev. A 33</em>(2), 1986, 1134:1140.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.neighborhood" href="#DelayEmbeddings.neighborhood"><code>DelayEmbeddings.neighborhood</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">neighborhood(point, tree, ntype)
neighborhood(point, tree, ntype, n::Int, w::Int = 1)</code></pre><p>Return a vector of indices which are the neighborhood of <code>point</code> in some <code>data</code>, where the <code>tree</code> was created using <code>tree = KDTree(data [, metric])</code>. The <code>ntype</code> is the type of neighborhood and can be any subtype of <a href="#DelayEmbeddings.AbstractNeighborhood"><code>AbstractNeighborhood</code></a>.</p><p>Use the second method when the <code>point</code> belongs in the data, i.e. <code>point = data[n]</code>. Then <code>w</code> stands for the Theiler window (positive integer). Only points that have index <code>abs(i - n) ≥ w</code> are returned as a neighborhood, to exclude close temporal neighbors. The default <code>w=1</code> is the case of excluding the <code>point</code> itself.</p><p><strong>References</strong></p><p><code>neighborhood</code> simply interfaces the functions <code>knn</code> and <code>inrange</code> from <a href="https://github.com/KristofferC/NearestNeighbors.jl">NearestNeighbors.jl</a> by using the argument <code>ntype</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.orthonormal" href="#DelayEmbeddings.orthonormal"><code>DelayEmbeddings.orthonormal</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">orthonormal(D, k) -&gt; ws</code></pre><p>Return a matrix <code>ws</code> with <code>k</code> columns, each being an <code>D</code>-dimensional orthonormal vector.</p><p>Always returns <code>SMatrix</code> for stability reasons.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T" href="#DelayEmbeddings.reconstruct-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>DelayEmbeddings.reconstruct</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">reconstruct(s, γ, τ)</code></pre><p>Reconstruct <code>s</code> using the delay coordinates embedding with <code>γ</code> temporal neighbors and delay <code>τ</code> and return the result as a <a href="#DelayEmbeddings.Dataset"><code>Dataset</code></a>.</p><p>See <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a> for the version that accepts the embedding dimension <code>D = γ+1</code> directly.</p><p><strong>Description</strong></p><p><strong>Single Timeseries</strong></p><p>If <code>τ</code> is an integer, then the <span>$n$</span>-th entry of the embedded space is</p><div>\[(s(n), s(n+\tau), s(n+2\tau), \dots, s(n+γ\tau))\]</div><p>If instead <code>τ</code> is a vector of integers, so that <code>length(τ) == γ</code>, then the <span>$n$</span>-th entry is</p><div>\[(s(n), s(n+\tau[1]), s(n+\tau[2]), \dots, s(n+\tau[γ]))\]</div><p>The reconstructed dataset can have same invariant quantities (like e.g. lyapunov exponents) with the original system that the timeseries were recorded from, for proper <code>γ</code> and <code>τ</code>. This is known as the Takens embedding theorem [1, 2]. The case of different delay times allows reconstructing systems with many time scales, see [3].</p><p><em>Notice</em> - The dimension of the returned dataset (i.e. embedding dimension) is <code>γ+1</code>!</p><p><strong>Multiple Timeseries</strong></p><p>To make a reconstruction out of a multiple timeseries (i.e. trajectory) the number of timeseries must be known by type, so <code>s</code> can be either:</p><ul><li><code>s::AbstractDataset{B}</code></li><li><code>s::SizedAray{A, B}</code></li></ul><p>If the trajectory is for example <span>$(x, y)$</span> and <code>τ</code> is integer, then the <span>$n$</span>-th entry of the embedded space is</p><div>\[(x(n), y(n), x(n+\tau), y(n+\tau), \dots, x(n+γ\tau), y(n+γ\tau))\]</div><p>If <code>τ</code> is an <code>AbstractMatrix{Int}</code>, so that <code>size(τ) == (γ, B)</code>, then we have</p><div>\[(x(n), y(n), x(n+\tau[1, 1]), y(n+\tau[1, 2]), \dots, x(n+\tau[γ, 1]), y(n+\tau[γ, 2]))\]</div><p><em>Notice</em> - The dimension of the returned dataset is <code>(γ+1)*B</code>!</p><p><strong>References</strong></p><p>[1] : F. Takens, <em>Detecting Strange Attractors in Turbulence — Dynamical Systems and Turbulence</em>, Lecture Notes in Mathematics <strong>366</strong>, Springer (1981)</p><p>[2] : T. Sauer <em>et al.</em>, J. Stat. Phys. <strong>65</strong>, pp 579 (1991)</p><p>[3] : K. Judd &amp; A. Mees, <a href="https://www.sciencedirect.com/science/article/pii/S0167278997001188">Physica D <strong>120</strong>, pp 273 (1998)</a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.stochastic_indicator-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any}, Tuple{AbstractArray{T,1},Any,Any}} where T" href="#DelayEmbeddings.stochastic_indicator-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any}, Tuple{AbstractArray{T,1},Any,Any}} where T"><code>DelayEmbeddings.stochastic_indicator</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">stochastic_indicator(s::AbstractVector, τ:Int, γs = 1:4) -&gt; E₂s</code></pre><p>Compute an estimator for apparent randomness in a reconstruction with <code>γs</code> temporal neighbors.</p><p><strong>Description</strong></p><p>Given the scalar timeseries <code>s</code> and the embedding delay <code>τ</code> compute the values of <code>E₂</code> for each <code>γ ∈ γs</code>, according to Cao&#39;s Method (eq. 5 of [1]).</p><p>Use this function to confirm that the input signal is not random and validate the results of <a href="#DelayEmbeddings.estimate_dimension"><code>estimate_dimension</code></a>. In the case of random signals, it should be <code>E₂ ≈ 1 ∀ γ</code>.</p><p><strong>References</strong></p><p>[1] : Liangyue Cao, <a href="https://www.sciencedirect.com/science/article/pii/S0167278997001188?via%3Dihub">Physica D, pp. 43-50 (1997)</a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings._bisect-Union{Tuple{AbstractArray{T,1}}, Tuple{T}} where T" href="#DelayEmbeddings._bisect-Union{Tuple{AbstractArray{T,1}}, Tuple{T}} where T"><code>DelayEmbeddings._bisect</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">_bisect(s)</code></pre><p>Create a partition histogram of the sorted series <code>s</code> with a partition of its space defined by a recursive bisection method. The first level partition divides <code>s</code> in two segments with equal number of points; each partition is divided into two further sub-pantitions, etc., until the distribution of the points in the highest level subpartition is homogeneous.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings._equalbins-Union{Tuple{AbstractArray{T,1}}, Tuple{T}} where T" href="#DelayEmbeddings._equalbins-Union{Tuple{AbstractArray{T,1}}, Tuple{T}} where T"><code>DelayEmbeddings._equalbins</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">_equalbins(s[; nbins, binwidth])</code></pre><p>Create a histogram of the sorted series <code>s</code> with bins of the same width. Either the number of bins (<code>nbins</code>) or their width (<code>binwidth</code>) must be given as keyword argument (<strong>but not both</strong>).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings._frequencies!-Union{Tuple{T}, Tuple{AbstractArray{T,1},AbstractArray{T,1} where T,AbstractArray{T,1} where T}} where T" href="#DelayEmbeddings._frequencies!-Union{Tuple{T}, Tuple{AbstractArray{T,1},AbstractArray{T,1} where T,AbstractArray{T,1} where T}} where T"><code>DelayEmbeddings._frequencies!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">_frequencies!(f, s, edges)</code></pre><p>Calculate a histogram of values of <code>s</code> along the bins defined by <code>edges</code>. Both <code>s</code> and <code>edges</code> must be sorted ascendingly. The frequencies (counts) of <code>s</code> in each bin will be stored in the pre-allocated vector <code>f</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings._mutualinfo!-Tuple{AbstractArray{T,1} where T,AbstractArray{T,1} where T,AbstractArray{#s830,1} where #s830&lt;:Integer,AbstractArray{T,1} where T}" href="#DelayEmbeddings._mutualinfo!-Tuple{AbstractArray{T,1} where T,AbstractArray{T,1} where T,AbstractArray{#s830,1} where #s830&lt;:Integer,AbstractArray{T,1} where T}"><code>DelayEmbeddings._mutualinfo!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">_mutualinfo!(f, sτ, edges, bins0)</code></pre><p>Calculate the mutual information between the distribution of the delayed time series <code>sτ</code> and its original image.</p><p>The two series are partitioned in a joint histogram with axes divided by the points given in <code>edges</code>; the distribution of the original image is given by <code>bins0</code>. The values of <code>sτ</code> must be arranged such that all the points of the bin <code>(1,j)</code> are contained in the first <code>bins0[1]</code> positions, the points of the bin <code>(2,j) are contained in the following</code>bins[2]` positions, etc.</p><p>The vector <code>f</code> is used as a placeholder to pre-allocate the histogram.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings._uniformtest-Tuple{Any}" href="#DelayEmbeddings._uniformtest-Tuple{Any}"><code>DelayEmbeddings._uniformtest</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">_uniformtest(s)</code></pre><p>Test uniformity in the values of the sorted vector <code>s</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.afnn-Union{Tuple{T}, Tuple{AbstractArray{T,1},Int64}, Tuple{AbstractArray{T,1},Int64,Any}, Tuple{AbstractArray{T,1},Int64,Any,Any}} where T" href="#DelayEmbeddings.afnn-Union{Tuple{T}, Tuple{AbstractArray{T,1},Int64}, Tuple{AbstractArray{T,1},Int64,Any}, Tuple{AbstractArray{T,1},Int64,Any,Any}} where T"><code>DelayEmbeddings.afnn</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">afnn(s::AbstractVector, τ:Int, γs = 1:5, metric=Euclidean())</code></pre><p>Compute the parameter E₁ of Cao&#39;s &quot;averaged false nearest neighbors&quot; method for determining the minimum embedding dimension of the time series <code>s</code>, with a sequence of <code>τ</code>-delayed temporal neighbors [1].</p><p><strong>Description</strong></p><p>Given the scalar timeseries <code>s</code> and the embedding delay <code>τ</code> compute the values of <code>E₁</code> for each <code>γ ∈ γs</code>, according to Cao&#39;s Method (eq. 3 of [1]).</p><p>This quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the number of temporal neighbors changes from <code>γ</code> to <code>γ+1</code>.</p><p>Please be aware that in <strong>DynamicalSystems.jl</strong> <code>γ</code> stands for the amount of temporal neighbors and not the embedding dimension (<code>D = γ + 1</code>, see also <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>).</p><p>Return the vector of all computed <code>E₁</code>s. To estimate a good value for <code>γ</code> from this, find <code>γ</code> for which the value <code>E₁</code> saturates at some value around 1.</p><p><em>Note: This method does not work for datasets with perfectly periodic signals.</em></p><p>See also: <a href="#DelayEmbeddings.estimate_dimension"><code>estimate_dimension</code></a>, <a href="#DelayEmbeddings.fnn"><code>fnn</code></a>, <a href="#DelayEmbeddings.f1nn"><code>f1nn</code></a>.</p><p><strong>References</strong></p><p>[1] : Liangyue Cao, <a href="https://www.sciencedirect.com/science/article/pii/S0167278997001188?via%3Dihub">Physica D, pp. 43-50 (1997)</a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.f1nn" href="#DelayEmbeddings.f1nn"><code>DelayEmbeddings.f1nn</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">f1nn(s::AbstractVector, τ:Int, γs = 1:5, metric = Euclidean())</code></pre><p>Calculate the ratio of &quot;false first nearest neighbors&quot; (FFNN) of the datasets created from <code>s</code> with a sequence of <code>τ</code>-delayed temporal neighbors.</p><p><strong>Description</strong></p><p>Given a dataset made by embedding <code>s</code> with <code>γ</code> temporal neighbors and delay <code>τ</code>, the &quot;first nearest neighbors&quot; (FFNN) are the pairs of points that are nearest to each other at dimension <code>γ</code> that cease to be nearest neighbors at dimension <code>γ+1</code> [1].</p><p>The returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each <code>γ ∈ γs</code>. The optimal value for <code>γ</code> is found at the point where this ratio approaches zero.</p><p>Please be aware that in <strong>DynamicalSystems.jl</strong> <code>γ</code> stands for the amount of temporal neighbors and not the embedding dimension (<code>D = γ + 1</code>, see also <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>).</p><p>See also: <a href="#DelayEmbeddings.estimate_dimension"><code>estimate_dimension</code></a>, <a href="#DelayEmbeddings.afnn-Union{Tuple{T}, Tuple{AbstractArray{T,1},Int64}, Tuple{AbstractArray{T,1},Int64,Any}, Tuple{AbstractArray{T,1},Int64,Any,Any}} where T"><code>afnn</code></a>, <a href="#DelayEmbeddings.fnn"><code>fnn</code></a>.</p><p><strong>References</strong></p><p>[1] : Anna Krakovská <em>et al.</em>, &quot;Use of false nearest neighbours for selecting variables and embedding parameters for state space reconstruction&quot;, <em>J Complex Sys</em> 932750 (2015), DOI: 10.1155/2015/932750</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.fnn" href="#DelayEmbeddings.fnn"><code>DelayEmbeddings.fnn</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">fnn(s::AbstractVector, τ:Int, γs = 1:5; rtol=10.0, atol=2.0)</code></pre><p>Calculate the number of &quot;false nearest neighbors&quot; (FNN) of the datasets created from <code>s</code> with a sequence of <code>τ</code>-delayed temporal neighbors.</p><p><strong>Description</strong></p><p>Given a dataset made by embedding <code>s</code> with <code>γ</code> temporal neighbors and delay <code>τ</code>, the &quot;false nearest neighbors&quot; (FNN) are the pairs of points that are nearest to each other at dimension <code>γ</code>, but are separated at dimension <code>γ+1</code>. Kennel&#39;s criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors (<code>rtol</code>, eq. 4 in [1]), and another threshold for the ratio between the increased distance and the &quot;size of the attractor&quot; (<code>atol</code>, eq. 5 in [1]). These thresholds are given as keyword arguments.</p><p>The returned value is a vector with the number of FNN for each <code>γ ∈ γs</code>. The optimal value for <code>γ</code> is found at the point where the number of FNN approaches zero.</p><p>Please be aware that in <strong>DynamicalSystems.jl</strong> <code>γ</code> stands for the amount of temporal neighbors and not the embedding dimension (<code>D = γ + 1</code>, see also <a href="#DelayEmbeddings.embed-Tuple{Any,Any,Any}"><code>embed</code></a>).</p><p>See also: <a href="#DelayEmbeddings.estimate_dimension"><code>estimate_dimension</code></a>, <a href="#DelayEmbeddings.afnn-Union{Tuple{T}, Tuple{AbstractArray{T,1},Int64}, Tuple{AbstractArray{T,1},Int64,Any}, Tuple{AbstractArray{T,1},Int64,Any,Any}} where T"><code>afnn</code></a>, <a href="#DelayEmbeddings.f1nn"><code>f1nn</code></a>.</p><p><strong>References</strong></p><p>[1] : M. Kennel <em>et al.</em>, &quot;Determining embedding dimension for phase-space reconstruction using a geometrical construction&quot;, <em>Phys. Review A 45</em>(6), 3403-3411 (1992).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.localextrema-Tuple{Any}" href="#DelayEmbeddings.localextrema-Tuple{Any}"><code>DelayEmbeddings.localextrema</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">localextrema(y) -&gt; max_ind, min_ind</code></pre><p>Find the local extrema of given array <code>y</code>, by scanning point-by-point. Return the indices of the maxima (<code>max_ind</code>) and the indices of the minima (<code>min_ind</code>).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DelayEmbeddings.svd-Tuple{AbstractDataset}" href="#DelayEmbeddings.svd-Tuple{AbstractDataset}"><code>DelayEmbeddings.svd</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">svd(d::AbstractDataset) -&gt; U, S, Vtr</code></pre><p>Perform singular value decomposition on the dataset.</p></div></div></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
